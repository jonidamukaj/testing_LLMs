Our study examines the evolution of Language Models (LLMs) and compares their
effectiveness in addressing gender bias and hallucination tendencies between different
prompt templates, authors and models. We use both automated metrics and human
evaluators to assess text quality, present empirical results, and analyze implications.
Visual representations will be used to illustrate differences in text generation
