import json
import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag
from collections import Counter

# Load the data from the JSON file
with open('prompt1_FEW.json') as file:
    data = json.load(file)

adjectives_per_author = {}

for author_data in data:
    author_name = author_data['name']
    existing_text = author_data['existing_text']
    generated_texts = [author_data[f'generated_text{i+1}'] for i in range(4)]

    # Tokenize and tag the words in the existing text
    existing_words = word_tokenize(existing_text)
    existing_tagged_words = pos_tag(existing_words)

    # Collect the adjectives from the existing text
    existing_adjectives = [word for word, pos in existing_tagged_words if pos.startswith('JJ')]

    # Collect the adjectives from the generated texts
    generated_adjectives = []
    for generated_text in generated_texts:
        generated_words = word_tokenize(generated_text)
        generated_tagged_words = pos_tag(generated_words)
        generated_adjectives.extend([word for word, pos in generated_tagged_words if pos.startswith('JJ')])

    # Count the occurrences of each adjective
    adjective_counts = Counter(existing_adjectives + generated_adjectives)

    # Store the adjective counts for the author
    adjectives_per_author[author_name] = adjective_counts

# Save the adjectives per author in a JSON file
output_data = {'adjectives_per_author': adjectives_per_author}

with open('adjectivesFEW.json', 'w') as output_file:
    json.dump(output_data, output_file, indent=4)

print("Adjectives per author have been saved in adjectivesFEW.json.")
