{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjectives per author have been saved in adjectivesFEW.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('turbo_Results.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "adjectives_per_author = {}\n",
    "\n",
    "for author_data in data:\n",
    "    author_name = author_data['name']\n",
    "    existing_text = author_data['existing_text']\n",
    "    generated_texts = [author_data[f'generated_text{i+1}'] for i in range(2)]\n",
    "\n",
    "    # Tokenize and tag the words in the existing text\n",
    "    existing_words = word_tokenize(existing_text)\n",
    "    existing_tagged_words = pos_tag(existing_words)\n",
    "\n",
    "    # Collect the adjectives from the existing text\n",
    "    existing_adjectives = [word for word, pos in existing_tagged_words if pos.startswith('JJ')]\n",
    "\n",
    "    # Collect the adjectives from the generated texts\n",
    "    generated_adjectives = []\n",
    "    for generated_text in generated_texts:\n",
    "        generated_words = word_tokenize(generated_text)\n",
    "        generated_tagged_words = pos_tag(generated_words)\n",
    "        generated_adjectives.extend([word for word, pos in generated_tagged_words if pos.startswith('JJ')])\n",
    "\n",
    "    # Count the occurrences of each adjective\n",
    "    adjective_counts = Counter(existing_adjectives + generated_adjectives)\n",
    "\n",
    "    # Store the adjective counts for the author\n",
    "    adjectives_per_author[author_name] = adjective_counts\n",
    "\n",
    "# Save the adjectives per author in a JSON file\n",
    "output_data = {'adjectives_per_author': adjectives_per_author}\n",
    "\n",
    "with open('adjTurbo.json', 'w') as output_file:\n",
    "    json.dump(output_data, output_file, indent=4)\n",
    "\n",
    "print(\"Adjectives per author have been saved in adjectivesFEW.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to combined_adjective.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the filenames of the JSON files for each model\n",
    "json_files = {\n",
    "    'ada': 'adjAda.json',\n",
    "    'curie': 'adjCurie.json',\n",
    "    'turbo': 'adjTurbo.json',\n",
    "    'davinci': 'adjDavinci.json'\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store the combined adjectives for each author\n",
    "combined_adjectives = {}\n",
    "\n",
    "# Read and merge adjectives from all models\n",
    "for model, file_name in json_files.items():\n",
    "    with open(file_name, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for author, adjectives in data['adjectives_per_author'].items():\n",
    "            if author not in combined_adjectives:\n",
    "                combined_adjectives[author] = {}\n",
    "            combined_adjectives[author][model] = list(adjectives.keys())\n",
    "\n",
    "# Define the output JSON file\n",
    "output_json_file = 'combined_adjective.json'\n",
    "\n",
    "# Save the combined data to a JSON file\n",
    "with open(output_json_file, 'w') as json_output:\n",
    "    json.dump(combined_adjectives, json_output, indent=4)\n",
    "\n",
    "print(f'Combined data has been saved to {output_json_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "# Load the data from the JSON file\n",
    "with open('combined_adjective.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate through each author and their data\n",
    "for author, models in data.items():\n",
    "    for model, adjectives in models.items():\n",
    "        # Calculate the number of adjectives\n",
    "        num_adjectives = len(adjectives)\n",
    "        \n",
    "        # Find the two most used adjectives\n",
    "        adjectives_counts = {}\n",
    "        for adjective in adjectives:\n",
    "            adjectives_counts[adjective] = adjectives_counts.get(adjective, 0) + 1\n",
    "        \n",
    "        most_used_adjectives = sorted(adjectives_counts.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "        \n",
    "        # Prepare a row for CSV\n",
    "        row = [author, model, num_adjectives]\n",
    "        for adj, count in most_used_adjectives:\n",
    "            row.extend([adj, count])\n",
    "        \n",
    "        # Append the row to the results list\n",
    "        results_list.append(row)\n",
    "\n",
    "# Define the CSV file header\n",
    "header = [\"Author\", \"Model\", \"Num_Adjectives\", \"Top_Adjective_1\",\"Top_Adjective_2\"]\n",
    "\n",
    "# Save the results to a CSV file\n",
    "with open(\"results.csv\", \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(results_list)\n",
    "\n",
    "print(\"Results saved to 'results.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate CSV files created for each model.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the input CSV file path\n",
    "input_file = \"results.csv\"\n",
    "\n",
    "# Define the models for which you want to create separate CSV files\n",
    "models = [\"ada\", \"davinci\", \"curie\", \"turbo\"]\n",
    "\n",
    "# Iterate through each model and create a separate CSV file\n",
    "for model in models:\n",
    "    # Define the output CSV file path for the current model\n",
    "    output_file = f\"{model}_output.csv\"\n",
    "    \n",
    "    # Open the input and output CSV files\n",
    "    with open(input_file, \"r\") as csvfile, open(output_file, \"w\", newline=\"\") as outfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Define the headers for the output CSV file\n",
    "        fieldnames = [\"Author\", \"Num_Adjectives\", \"Top_Adjective_1\", \"Top_Adjective_2\"]\n",
    "        \n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Iterate through the rows in the input CSV file\n",
    "        for row in reader:\n",
    "            if row[\"Model\"] == model:\n",
    "                # Write the filtered rows to the output CSV file\n",
    "                writer.writerow({\n",
    "                    \"Author\": row[\"Author\"],\n",
    "                    \"Num_Adjectives\": row[\"Num_Adjectives\"],\n",
    "                    \"Top_Adjective_1\": row[\"Top_Adjective_1\"],\n",
    "                    \"Top_Adjective_2\": row[\"Top_Adjective_2\"]\n",
    "                })\n",
    "\n",
    "print(\"Separate CSV files created for each model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
